<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 3A - Image Warping and Mosaicing</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #003262;
            text-align: center;
            margin-bottom: 10px;
            border-bottom: 3px solid #FDB515;
            padding-bottom: 20px;
        }
        h2 {
            color: #003262;
            margin-top: 40px;
            padding-bottom: 10px;
            border-bottom: 2px solid #FDB515;
        }
        h3 {
            color: #003262;
            margin-top: 30px;
        }
        .section {
            margin: 30px 0;
        }
        .image-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .image-container {
            text-align: center;
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #e9ecef;
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .image-caption {
            margin-top: 10px;
            font-style: italic;
            color: #666;
        }
        .placeholder {
            background: #e9ecef;
            padding: 60px 20px;
            text-align: center;
            color: #6c757d;
            border-radius: 4px;
            border: 2px dashed #adb5bd;
        }
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }
        pre {
            background: #f4f4f4;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            border-left: 4px solid #FDB515;
        }
        .back-link {
            display: inline-block;
            margin-bottom: 20px;
            color: #003262;
            text-decoration: none;
            font-weight: bold;
        }
        .back-link:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="../" class="back-link">← Back to Portfolio</a>

        <h1>Project 3A: Image Warping and Mosaicing</h1>
        <p style="text-align: center; color: #666;">CS180/280A: Intro to Computer Vision and Computational Photography</p>

        <div class="section">
            <h2>Overview</h2>
            <p>
                This project explores image warping and mosaicing techniques. The goal is to take two or more photographs
                and create an image mosaic by registering, projective warping, resampling, and compositing them.
                Along the way, I learn how to compute homographies and use them to warp images.
            </p>
        </div>

        <!-- Part A.1: Shoot the Pictures -->
        <div class="section">
            <h2>Part A.1: Shoot the Pictures (20 pts)</h2>
            <p>
                I captured multiple sets of photographs with projective transformations between them by fixing the center
                of projection and rotating the camera while capturing photos.
            </p>

            <h3>Image Set 1 - BAIR</h3>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/BAIR_left.jpg" alt="BAIR left view">
                    <p class="image-caption">BAIR left view</p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/BAIR_right.jpg" alt="BAIR right view">
                    <p class="image-caption">BAIR right view</p>
                </div>
            </div>

            <h3>Image Set 2 - Bowles</h3>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/bowles_left.jpg" alt="Bowles left view">
                    <p class="image-caption">Bowles left view</p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/bowles_right.jpg" alt="Bowles right view">
                    <p class="image-caption">Bowles right view</p>
                </div>
            </div>
        </div>

        <!-- Part A.2: Recover Homographies -->
        <div class="section">
            <h2>Part A.2: Recover Homographies (20 pts)</h2>
            <p>
                I implemented the <code>computeH(im1_pts, im2_pts)</code> function to recover homography matrices
                from corresponding point pairs. The function sets up a system of linear equations and solves it
                using least-squares to handle overdetermined systems.
            </p>

            <h3>Point Correspondences</h3>
            <div class="image-container" style="margin: 20px 0;">
                <img src="media/part1/source/bair_bowles_corr.png" alt="BAIR and Bowles correspondences">
                <p class="image-caption">Point correspondences for BAIR (top) and Bowles (bottom) image pairs</p>
            </div>

            <h3>System of Equations</h3>
            <p>The homography matrix H transforms points from one image to another:</p>
            <pre>
H = [A  B  C]       [X]     [X']
    [D  E  F]   ×   [Y]  =  [Y']
    [G  H  1]       [1]     [S ]
            </pre>

            <p>This gives us the projective transformation:</p>
            <pre>
AX + BY + C = X'
DX + EY + F = Y'
GX + HY + 1 = S

Therefore:
X' = (AX + BY + C) / (GX + HY + 1)
Y' = (DX + EY + F) / (GX + HY + 1)
            </pre>

            <p>Rearranging to eliminate the division (multiplying both sides by the denominator):</p>
            <pre>
X'(GX + HY + 1) = (AX + BY + C)
Y'(GX + HY + 1) = (DX + EY + F)

Expanding:
G(XX') + H(X'Y) + X' = AX + BY + C
G(Y'X) + H(YY') + Y' = DX + EY + F

Rearranging to equal zero:
AX + BY + C - G(XX') - H(X'Y) - X' = 0
-DX - EY - F + G(Y'X) + H(YY') + Y' = 0
            </pre>

            <p>For each correspondence point (X, Y) → (X', Y'), we get two equations.
               We can express this in matrix form <strong>Ah = 0</strong>, where:</p>
            <pre>
h = [A, B, C, D, E, F, G, H, 1]<sup>T</sup>  (9 elements, 8 degrees of freedom)

A = [X   Y   1   0   0   0   -XX'  -X'Y  -X' ]
    [0   0   0   X   Y   1   -Y'X  -YY'  -Y' ]
    </pre>

            <p>With n correspondence points, we stack n such pairs of rows to form an overdetermined system (2n equations, 8 unknowns).
               We solve this using <strong>least squares</strong>:</p>
            <pre>
Minimize ||Ah||² subject to ||h|| = 1

This corresponds to finding the eigenvector with the smallest eigenvalue of A<sup>T</sup>A,
which is equivalent to the right singular vector corresponding to the smallest
singular value in the SVD of A (the rightmost column of V).
            </pre>
        </div>

        <!-- Part A.3: Warp the Images -->
        <div class="section">
            <h2>Part A.3: Warp the Images (20 pts)</h2>
            <p>
                I implemented two interpolation methods from scratch:
            </p>
            <ul>
                <li><code>warpImageNearestNeighbor(im, H)</code> - Rounds coordinates to nearest pixel</li>
                <li><code>warpImageBilinear(im, H)</code> - Uses weighted average of four neighboring pixels</li>
            </ul>
            <p>Both functions use inverse warping to avoid holes in the output image.</p>

            <h3>Rectification Examples</h3>
            <div class="image-container" style="margin: 20px 0;">
                <img src="media/part1/source/warp.png" alt="Rectification comparison">
                <p class="image-caption">Top row: Tiles1 original, nearest neighbor, and bilinear interpolation<br>
                Bottom row: Tiles2 original, nearest neighbor, and bilinear interpolation</p>
            </div>

            <h3>Comparison and Discussion</h3>
            <div class="image-container" style="margin: 20px 0;">
                <img src="media/part1/source/zoom.png" alt="Zoomed comparison of interpolation methods">
                <p class="image-caption">Zoomed-in comparison showing interpolation differences</p>
            </div>

            <p>
                The comparison between nearest neighbor and bilinear interpolation reveals important trade-offs:
            </p>

            <p>
                <strong>Image Quality:</strong> Bilinear interpolation produces noticeably smoother results with more
                natural-looking transitions between pixels. In contrast, nearest neighbor interpolation exhibits
                significant aliasing artifacts, creating a "blocky" or "pixelated" appearance, especially visible
                in the zoomed view above. This is because nearest neighbor simply copies the value of the closest
                source pixel, while bilinear interpolation computes a weighted average of the four surrounding pixels,
                creating smoother gradients.
            </p>

            <p>
                <strong>Computational Speed:</strong> Nearest neighbor is computationally faster since it requires
                only a single pixel lookup and rounding operation. Bilinear interpolation requires four pixel lookups
                and weighted averaging calculations, making it roughly 4x slower. However, for most modern applications,
                this speed difference is negligible compared to the quality improvement.
            </p>

            <p>
                <strong>Edge Preservation:</strong> While nearest neighbor better preserves sharp edges (no blurring),
                it introduces jagged "staircase" artifacts along diagonal lines. Bilinear interpolation smooths these
                edges but can introduce slight blurring. For rectification tasks like ours, the smoother appearance
                of bilinear interpolation is generally preferred over the harsh aliasing of nearest neighbor.
            </p>
        </div>

        <!-- Part A.4: Blend the Images into a Mosaic -->
        <div class="section">
            <h2>Part A.4: Blend the Images into a Mosaic (20 pts)</h2>
            <p>
                I created image mosaics by warping images into alignment and blending them using weighted averaging
                to reduce edge artifacts.
            </p>

            <h3>Mosaic 1 - BAIR</h3>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/BAIR_left.jpg" alt="BAIR left source">
                    <p class="image-caption">BAIR left view</p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/BAIR_right.jpg" alt="BAIR right source">
                    <p class="image-caption">BAIR right view</p>
                </div>
            </div>
            <div class="image-container" style="margin-top: 20px;">
                <img src="media/part1/source/bair_mosaic.png" alt="BAIR mosaic result">
                <p class="image-caption">BAIR mosaic - blended result</p>
            </div>

            <h3>Mosaic 2 - Bowles</h3>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/bowles_left.jpg" alt="Bowles left source">
                    <p class="image-caption">Bowles left view</p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/bowles_right.jpg" alt="Bowles right source">
                    <p class="image-caption">Bowles right view</p>
                </div>
            </div>
            <div class="image-container" style="margin-top: 20px;">
                <img src="media/part1/source/bowles_mosaic.png" alt="Bowles mosaic result">
                <p class="image-caption">Bowles mosaic - blended result</p>
            </div>

            <h3>Mosaic 3 - Room</h3>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/room_left.jpg" alt="Room left source">
                    <p class="image-caption">Room left view</p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/room_right.jpg" alt="Room right source">
                    <p class="image-caption">Room right view</p>
                </div>
            </div>
            <div class="image-container" style="margin-top: 20px;">
                <img src="media/part1/source/room_mosaic.png" alt="Room mosaic result">
                <p class="image-caption">Room mosaic - blended result</p>
            </div>

            <h3>Blending Procedure</h3>
            <p>
                To create seamless mosaics without visible seams, I implemented a <strong>linear feathering</strong>
                technique using alpha channel blending with a configurable blend width of 150 pixels.
            </p>

            <p>
                <strong>Algorithm Overview:</strong>
            </p>
            <ol>
                <li>
                    <strong>Warp the left image:</strong> First, I warp the left image using the computed homography
                    with bilinear interpolation to align it with the right image. Both images are placed on a canvas
                    large enough to hold both.
                </li>
                <li>
                    <strong>Create alpha masks:</strong>
                    <ul style="margin-top: 10px;">
                        <li>
                            <strong>Left image alpha:</strong> For each row, I identify the rightmost non-black pixel
                            of the warped left image. The alpha value is set to 1.0 throughout most of the image,
                            then linearly fades from 1.0 to 0.0 over the rightmost 150 pixels. This creates a smooth
                            transition zone on the right edge where the images overlap.
                        </li>
                        <li>
                            <strong>Right image alpha:</strong> The alpha mask starts at 0.0 on the leftmost edge
                            and linearly increases to 1.0 over the first 150 pixels, remaining at 1.0 for the rest
                            of the image. This complements the left image's fade.
                        </li>
                    </ul>
                </li>
            </ol>
        </div>

        <!-- Project 3B: Automatic Stitching Pipeline -->
        <div class="section">
            <h2>Project 3B: Automatic Feature Matching and Mosaicing</h2>
            <p>
                This follow-up extends the mosaicing pipeline with fully automatic feature detection,
                matching, and robust alignment inspired by Brown et al.'s “Multi-Image Matching using
                Multi-Scale Oriented Patches.” Each subsection documents the implementation decisions and
                the resulting visual evidence from the finished pipeline.
            </p>

            <h3>B.1: Harris Corner Detection (20 pts)</h3>
            <p>
                I revisited the Harris Interest Point Detector at a single scale and paired it with Adaptive
                Non-Maximal Suppression (ANMS) to retain spatially distributed keypoints. The figure below
                shows the Harris response heatmap and all candidate corners before ranking.
            </p>
            <div class="image-container">
                <img src="media/part1/source/all_harris.png" alt="Harris response and detected corners">
                <p class="image-caption">
                    Harris detector output showing response heatmap (left) and the initial pool of interest points (right) prior to ranking.
                </p>
            </div>
            <p>
                To highlight why ANMS matters, both figures below keep the top <code>K = 30</code> corners. Raw Harris scoring
                clusters points wherever texture is dense, whereas ANMS spreads responses across the scene.
            </p>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/strongest_harris_corners.png" alt="Top K Harris corners by score">
                    <p class="image-caption">
                        Top <code>K = 30</code> corners chosen purely by Harris response cluster heavily in textured regions.
                    </p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/anms_corners.png" alt="Corners retained after ANMS">
                    <p class="image-caption">
                        ANMS with <code>K = 30</code> enforces spatial separation, keeping points from collapsing onto the same area.
                    </p>
                </div>
            </div>

            <h3>B.2: Feature Descriptor Extraction (20 pts)</h3>
            <p>
                For each surviving feature, I extract an axis-aligned 8×8 descriptor sampled from a blurred
                40×40 window, followed by bias/gain normalization so descriptors become illumination invariant.
                The gallery highlights six representative patches visualized as intensity grids.
            </p>
            <div class="image-container">
                <img src="media/part1/source/8x8patches.png" alt="Sample normalized 8x8 feature descriptors">
                <p class="image-caption">
                    Six normalized 8×8 descriptors sampled from 40×40 windows; values are visualized as intensity grids after bias/gain normalization.
                </p>
            </div>

            <h3>B.3: Feature Matching (20 pts)</h3>
            <p>
                Descriptor vectors are matched via nearest neighbors in Euclidean space, and Lowe’s ratio test
                prunes ambiguous correspondences before anything reaches RANSAC. The surviving matches, shown below,
                already form coherent geometric structures across scenes.
            </p>
            <div class="image-container">
                <img src="media/part1/source/all_features.png" alt="Feature matches filtered with Lowe ratio test">
                <p class="image-caption">
                    Lowe ratio test matches between a representative image pair; colored lines connect descriptors that passed the ratio threshold.
                </p>
            </div>

            <h3>B.4: RANSAC for Robust Homography (40 pts)</h3>
            <p>
                A 4-point RANSAC loop robustly estimates homographies from the filtered matches and feeds them into
                the existing warping/blending pipeline, enabling fully automatic mosaics that can be compared directly
                with the manually aligned results from Part A.
            </p>
            <p>
                I implemented a minimal 4-point RANSAC loop that repeatedly samples correspondences, solves for the
                homography via DLT, and scores inliers with a 2-pixel reprojection threshold. The best homography then
                feeds back into the Part A warping/blending code to generate fully automatic mosaics. Below each scene
                shows the manually aligned reference mosaic next to the automatic result.
            </p>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/bair_mosaic.png" alt="BAIR manual mosaic">
                    <p class="image-caption">
                        BAIR manual mosaic (hand-picked correspondences, weighted feather blend).
                    </p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/bair_auto.png" alt="BAIR automatic mosaic">
                    <p class="image-caption">
                        BAIR automatic mosaic using Harris+ANMS, descriptors, Lowe matching, and 4-point RANSAC.
                    </p>
                </div>
            </div>
            <p class="image-caption" style="text-align:center;margin-top:-10px;">
                Automatic alignment smooths the skyline/roof transition and removes the slight waviness the manual blend left in the city façade and sky.
            </p>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/bowles_mosaic.png" alt="Bowles manual mosaic">
                    <p class="image-caption">
                        Bowles manual mosaic assembled with interactive correspondences.
                    </p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/bowles_auto.png" alt="Bowles automatic mosaic">
                    <p class="image-caption">
                        Bowles automatic mosaic computed from feature matches and RANSAC-estimated homography.
                    </p>
                </div>
            </div>
            <p class="image-caption" style="text-align:center;margin-top:-10px;">
                The automatic mosaic noticeably reduces jitter along the tree canopy overlap where manual correspondences struggled.
            </p>
            <div class="image-grid">
                <div class="image-container">
                    <img src="media/part1/source/room_mosaic.png" alt="Room manual mosaic">
                    <p class="image-caption">
                        Room manual mosaic baseline from Part A.
                    </p>
                </div>
                <div class="image-container">
                    <img src="media/part1/source/room_auto.png" alt="Room automatic mosaic">
                    <p class="image-caption">
                        Room automatic mosaic showcasing the end-to-end pipeline on a challenging indoor scene.
                    </p>
                </div>
            </div>
            <p class="image-caption" style="text-align:center;margin-top:-10px;">
                Automatic stitching reveals remaining weaknesses: verticals inherit a slight curvature and the cup picks up small jitter compared to the manual reference.
            </p>
        </div>

        <!-- Conclusion -->
        <div class="section">
            <h2>What I Learned</h2>
            <p>
                This project taught me valuable lessons about approaching mathematical computer vision problems
                effectively. The most important insight was the critical importance of <strong>starting on paper</strong>
                before diving into code. Taking the time to fully understand the mathematical foundations (deriving
                the homography equations, understanding how the projective transformation works, and working through
                the linear algebra by hand) made the implementation phase significantly smoother and more intuitive.
            </p>
            <p>
                During implementation, I discovered that adopting a <strong>highly iterative development style with
                short feedback cycles</strong> was essential for success. Rather than writing large blocks of code
                and hoping they would work, I broke the project into small, testable components: first computing
                homographies on simple test cases, then implementing and verifying nearest neighbor interpolation
                before moving to bilinear, and finally tackling the blending incrementally. This iterative approach
                allowed me to catch bugs early, validate intermediate results visually, and build confidence that
                each component was working correctly before moving forward. The ability to quickly test, debug, and
                refine made what could have been a frustrating debugging nightmare into a manageable and even
                enjoyable learning experience.
            </p>
        </div>

        <footer style="text-align: center; margin-top: 40px; color: #666; border-top: 1px solid #eee; padding-top: 20px;">
            <p>CS180/280A - Projects 3A &amp; 3B: Image Warping, Feature Matching, and Mosaicing</p>
        </footer>
    </div>
</body>
</html>
